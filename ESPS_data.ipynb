{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain url 92\n",
      "total url 13934\n",
      "no_duplicate 8721\n"
     ]
    }
   ],
   "source": [
    "from src import Tool, PolicyDeepthEnvFixCoordinate_singlefile\n",
    "name = 'ESPS_dataset/test_url'\n",
    "data = dict(Tool.LoadObj(name))\n",
    "total_url = 0\n",
    "domain_count = 0\n",
    "no_duplicate = []\n",
    "for i, hrefs in enumerate(list(data['href'])):\n",
    "    total_url +=len(hrefs)\n",
    "    domain_count +=1\n",
    "    for href in hrefs:\n",
    "        if not href in no_duplicate:\n",
    "            no_duplicate.append(href)\n",
    "print('domain url',domain_count)\n",
    "print('total url',total_url)\n",
    "print('no_duplicate',len(no_duplicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 114.0.5735\n",
      "[WDM] - Get LATEST chromedriver version for 114.0.5735 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\Kuma\\.wdm\\drivers\\chromedriver\\win32\\114.0.5735.90\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivepage 1272\n",
      "ans 8721\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "traindf = pd.read_csv(\"./dataset_google_search/google_search_rank_train - contain news.csv\")\n",
    "validf = pd.read_csv(\"./dataset_google_search/google_search_rank_vali - contain_news.csv\")\n",
    "# testdf = pd.read_csv(\"./dataset_google_search/newdata_test_20 - remove error url.csv\")\n",
    "testdf = pd.read_csv(\"./dataset_google_search/newdata_test - remove error url.csv\")\n",
    "env = PolicyDeepthEnvFixCoordinate_singlefile.Env(testdf, negativeReward=-0.1, rewardweight=0.1)\n",
    "positivepage,ans=env.GetPageANS(no_duplicate)\n",
    "print('positivepage',len(positivepage))\n",
    "print('ans',len(ans))\n",
    "env.webQuit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272\n",
      "1236\n"
     ]
    }
   ],
   "source": [
    "no_duplicate_positive = []\n",
    "print(len(positivepage))\n",
    "for posurl in positivepage:\n",
    "    if posurl not in no_duplicate_positive:\n",
    "        no_duplicate_positive.append(posurl)\n",
    "print(len(no_duplicate_positive))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8721 1236\n"
     ]
    }
   ],
   "source": [
    "no_duplicate_2 = [p[p.index(\":\"):] for p in no_duplicate]\n",
    "no_duplicate_positive_2 = [p[p.index(\":\"):] for p in no_duplicate_positive] #只看http後的網址\n",
    "print(len(no_duplicate_2),len(no_duplicate_positive_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negativepage len 8164\n",
      "positive len 557\n"
     ]
    }
   ],
   "source": [
    "negativepage = []\n",
    "newpositive = []\n",
    "for i,each_url in enumerate(no_duplicate_2):\n",
    "    if each_url not in no_duplicate_positive_2:\n",
    "        negativepage.append(no_duplicate[i])\n",
    "    else:\n",
    "        newpositive.append(no_duplicate[i])\n",
    "print('negativepage len',len(negativepage))\n",
    "print('positive len',len(newpositive))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2582\n"
     ]
    }
   ],
   "source": [
    "## train dataset down sample\n",
    "from sklearn.utils import resample\n",
    "# up_sample_positive = resample(no_duplicate_positive,n_samples=len(no_duplicate_positive)*2)\n",
    "# down_sample_negative = resample(negativepage,n_samples=len(up_sample_positive)*2)\n",
    "down_sample_negative = resample(negativepage,n_samples=len(no_duplicate_positive)*2)\n",
    "# print(len(up_sample_positive))\n",
    "print(len(down_sample_negative))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236\n"
     ]
    }
   ],
   "source": [
    "# save positive dataset\n",
    "import os\n",
    "positive_label = [1]*len(no_duplicate_positive)\n",
    "print(len(positive_label))\n",
    "data = {'url':no_duplicate_positive,'label':positive_label }\n",
    "df = pd.DataFrame(data)\n",
    "path = 'ESPS_dataset/new'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "df.to_csv('ESPS_dataset/new/test_positive.csv',index=False,encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n"
     ]
    }
   ],
   "source": [
    "# vali/test positive page all anchor(no contain all label data)\n",
    "# import os\n",
    "# positive_label = [1]*len(newpositive)\n",
    "# print(len(positive_label))\n",
    "# data = {'url':newpositive,'label':positive_label}\n",
    "# df = pd.DataFrame(data)\n",
    "# path = 'ESPS_dataset/new'\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "# df.to_csv('ESPS_dataset/new/test_positive(no contain all label).csv',index=False,encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8164\n"
     ]
    }
   ],
   "source": [
    "# vali/test negative page no down sampling\n",
    "negative_label = [0]*len(negativepage)\n",
    "print(len(negative_label))\n",
    "data = {'url':negativepage,'label':negative_label }\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('ESPS_dataset/new/test_negative_pre.csv',index=False,encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# negative page down sampling\n",
    "negative_label = [0]*len(down_sample_negative)\n",
    "print(len(negative_label))\n",
    "data = {'url':down_sample_negative,'label':negative_label }\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('ESPS_dataset/test92_negative_down.csv',index=False,encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8164\n",
      "1236\n"
     ]
    }
   ],
   "source": [
    "# vali/test concat positive and negative\n",
    "import pandas as pd\n",
    "df_pos = pd.read_csv('ESPS_dataset/new/test_positive.csv')\n",
    "df_neg = pd.read_csv('ESPS_dataset/new/test_negative_pre.csv')\n",
    "print(len(df_neg['url']))\n",
    "print(len(df_pos['url']))\n",
    "# total = pd.concat([df_pos,df_neg],ignore_index=True)\n",
    "# df_shuffled = total.sample(frac=1, random_state=42)  # frac=1 表示将全部数据进行打乱\n",
    "# df_shuffled.reset_index(drop=True, inplace=True)\n",
    "# df_shuffled.to_csv('ESPS_dataset/new/test_no_down_pre2.csv', index=False,encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# train concat positive and negative (1:2)\n",
    "import pandas as pd\n",
    "df_pos = pd.read_csv('ESPS_dataset/vali_positive(no contain all label).csv')\n",
    "df_neg = pd.read_csv('ESPS_dataset/vali_negative.csv')\n",
    "\n",
    "total = []\n",
    "for i in range(len(df_pos)):\n",
    "    pos_start = i+1\n",
    "    pos_end = i+2\n",
    "    neg_start = 2*i+1\n",
    "    neg_end = 2*i+3\n",
    "    total.append(pd.concat([df_pos.iloc[pos_start:pos_end],df_neg.iloc[neg_start:neg_end]],ignore_index=True))\n",
    "total_df = pd.concat(total,ignore_index=True)\n",
    "total_df.to_csv('ESPS_dataset/vali_no_down.csv',index=False,encoding='utf_8_sig')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testlist len 95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# testdf = pd.read_csv(\"./dataset_google_search/newdata_test - remove error url2.csv\")\n",
    "# testwebsiteInfo = testdf.groupby(\"Homepage\")\n",
    "# testlist = list(testwebsiteInfo.groups)[0:96]\n",
    "# print('testlist len',len(testlist))\n",
    "# new_test = []\n",
    "# for url in testlist:\n",
    "#     if url not in new_test:\n",
    "#         new_test.append(url)\n",
    "# print(len(new_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# vali = pd.read_csv(\"./ESPS_dataset/vali_positive_down.csv\")\n",
    "# vali_only_start_page = pd.read_csv(\"./ESPS_dataset/new/vali_positive(no contain all label).csv\")\n",
    "# collect_miss_vali = []\n",
    "# only_start_page = []\n",
    "# for url in vali_only_start_page['url']:\n",
    "#     only_start_page.append(url)\n",
    "# print(len(only_start_page))\n",
    "# for url in vali['url']:\n",
    "#     if url not in only_start_page:\n",
    "#         collect_miss_vali.append(url)\n",
    "# print(len(collect_miss_vali))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}